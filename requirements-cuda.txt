# pytorch
--extra-index-url https://download.pytorch.org/whl/cu128
torch==2.8.0+cu128
torchvision==0.23.0+cu128
onnxruntime-gpu==1.22.0
nvidia-nccl-cu12==2.27.3; sys_platform == "linux"
triton-windows==3.4.0.post20; sys_platform == "win32"

# optimizers
bitsandbytes==0.46.0 # bitsandbytes for 8-bit optimizers and weight quantization

# flash-attn
https://github.com/zzlol63/flash-attention-prebuild-wheels/releases/download/v0.1/flash_attn-2.8.2+cu128torch2.7-cp310-cp310-win_amd64.whl; sys_platform == "win32" and python_version == "3.10"
https://github.com/zzlol63/flash-attention-prebuild-wheels/releases/download/v0.1/flash_attn-2.8.2+cu128torch2.7-cp311-cp311-win_amd64.whl; sys_platform == "win32" and python_version == "3.11"
https://github.com/zzlol63/flash-attention-prebuild-wheels/releases/download/v0.1/flash_attn-2.8.2+cu128torch2.7-cp312-cp312-win_amd64.whl; sys_platform == "win32" and python_version == "3.12"
triton-windows==3.3.1.post19; sys_platform == "win32"
